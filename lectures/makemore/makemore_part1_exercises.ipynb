{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMHcteeYumZvtWRoc8XxaJ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamthedoan/nn-zero-to-hero/blob/master/lectures/makemore/makemore_part1_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8FIAsoU44TEl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the names.txt file from github\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ua3a9yp6AOL",
        "outputId": "706f2210-cbfc-4c80-c794-8432cd4a02b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-03 21:01:28--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-06-03 21:01:28 (4.40 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "words[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bjyOKVa6ETH",
        "outputId": "9c261e78-12ab-4b84-9600-852487bb80da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyqDZYdZ6Idw",
        "outputId": "913a2685-9aa0-4ab7-dbd7-136df945b032"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(len(w) for w in words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbALn7cH6Nco",
        "outputId": "4df37787-2ec1-4c86-dc31-a4b0bc2663cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(len(w) for w in words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ETc1X4e6P8n",
        "outputId": "eca49360-3262-4bd8-97ae-c6f22319b687"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?**"
      ],
      "metadata": {
        "id": "LM4ILxem6viu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of chars\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "chars = [\".\"] + chars\n",
        "\n",
        "# dict mapping char to index\n",
        "stoi = {s:i for i, s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "\n",
        "# dict mapping index to char\n",
        "itos = {i:s for s,i in stoi.items()}\n"
      ],
      "metadata": {
        "id": "B83Sc1uX6wQX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stoi)"
      ],
      "metadata": {
        "id": "xJtaSoQr6Sdb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(itos)"
      ],
      "metadata": {
        "id": "JMHi0VjH8e44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = {}\n",
        "for w in words[:5]:\n",
        "  # add start and end tokens\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    trigram = (ch1,ch2,ch3)\n",
        "    t[trigram] = t.get(trigram, 0) + 1"
      ],
      "metadata": {
        "id": "DmLFqMRc8guz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(t.items(), key = lambda kv: -kv[1])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ua910WHZ9vza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counting"
      ],
      "metadata": {
        "id": "2diMhIbKCMjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.ones(27,27,27, dtype=torch.int32)\n",
        "# , device = device\n",
        "\n",
        "N[0,0,0] = 0\n",
        "\n",
        "# counting the trigrams\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    N[ix1, ix2, ix3] += 1\n",
        "\n",
        "# P is N but all values are probabilities\n",
        "P = N / N.sum(dim = 2, keepdim = True)"
      ],
      "metadata": {
        "id": "nu540tiB-cMr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs92UHdg-z-M",
        "outputId": "1a8532f6-2f6f-477f-95ec-1e64cc84897f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 27, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function"
      ],
      "metadata": {
        "id": "F7vTwZZcCPpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(input):\n",
        "  log_likelihood = 0.0\n",
        "\n",
        "  # for calculating average\n",
        "  n = 0\n",
        "\n",
        "  # for w in [\"brandon\"]\n",
        "\n",
        "  for w in input:\n",
        "    chs = ['.'] + list(w) + ['.']\n",
        "    for ch1, ch2, ch3, in zip(chs, chs[1:], chs[2:]):\n",
        "      ix1 = stoi[ch1]\n",
        "      ix2 = stoi[ch2]\n",
        "      ix3 = stoi[ch3]\n",
        "      prob = P[ix1, ix2, ix3]\n",
        "      # print(f'{ch1}{ch2}{ch3}: {prob:.4f}')\n",
        "\n",
        "      logprob = torch.log(prob)\n",
        "      log_likelihood += logprob\n",
        "      n += 1\n",
        "\n",
        "  # higher log_likelihood better, log value closer to 0 means probability was higher\n",
        "  print(f'{log_likelihood=}')\n",
        "\n",
        "  # negative log likelihood\n",
        "  nll = -log_likelihood\n",
        "  print(f'{nll=}')\n",
        "\n",
        "  # normalized negative log likelihood, minimize this\n",
        "  print(f'{nll/n}')\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKE-Vdi9AGmq",
        "outputId": "1483ca78-83c7-4a5a-8af3-e4df608a5ca2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_likelihood=tensor(-6.2656)\n",
            "nll=tensor(6.2656)\n",
            "2.088524103164673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyJncSHdHMFY",
        "outputId": "925dd21f-4cc2-49d8-cf21-8cba5edda7ad"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_likelihood=tensor(-410414.9688)\n",
            "nll=tensor(410414.9688)\n",
            "2.092747449874878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling"
      ],
      "metadata": {
        "id": "jG9pfOn3E9k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = []\n",
        "\n",
        "for i in range(10):\n",
        "  out = []\n",
        "  ix1,ix2 = 0,0\n",
        "  while True:\n",
        "    p = P[ix1, ix2]\n",
        "    ix1 = ix2\n",
        "    ix2 = torch.multinomial(p, 1, replacement=True).item()\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "    out.append(itos[ix2])\n",
        "\n",
        "  names.append(\"\".join(out))\n",
        "\n",
        "print(names)\n",
        "loss_func(names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbPn56YVFBDU",
        "outputId": "015a1bd7-2729-4d29-85d4-0985f66920ce"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['zur', 'yelays', 'karigha', 'yrene', 'yariola', 'glce', 'trah', 'ulennakinn', 'xashadhir', 'daishia']\n",
            "log_likelihood=tensor(-130.2120)\n",
            "nll=tensor(130.2120)\n",
            "2.100193977355957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E02: split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?**"
      ],
      "metadata": {
        "id": "CA80Se3_H7Xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up inputs and outputs"
      ],
      "metadata": {
        "id": "WkrMMia4Yx5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create training set of bigrams (x,y)\n",
        "\n",
        "xs, ys = [],[]\n",
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    # print(ch1, ch2, ch3)\n",
        "    xs.append([ix1, ix2])\n",
        "    ys.append(ix3)\n",
        "\n",
        "xs = torch.tensor(xs, dtype = torch.int64)\n",
        "ys = torch.tensor(ys, dtype = torch.int64)"
      ],
      "metadata": {
        "id": "m0bXuiBHIA0i"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create NN–perform forward pass, softmax, loss, backward pass, update grad"
      ],
      "metadata": {
        "id": "TzqS1f5tY0kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# weights\n",
        "W = torch.randn((27*2), 27, requires_grad=True)\n",
        "\n",
        "num_pass = 200\n",
        "\n",
        "for i in range(num_pass):\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(xs, num_classes=27).float()\n",
        "  xenc = xenc.view(-1, 27*2)\n",
        "\n",
        "  # softmax, used for normalizing output to a probability distribution\n",
        "  logits = xenc @ W # predict log-counts\n",
        "  counts = torch.exp(logits) # counts, equivalent to N\n",
        "  probs = counts / counts.sum(dim = 1, keepdims = True) # probabilites for next character\n",
        "\n",
        "  # loss (negative log likelihood)\n",
        "  loss = -probs[torch.arange(len(xs)),ys].log().mean()\n",
        "\n",
        "  # regularization: incentivizes W to be near 0 --> smoothing\n",
        "  loss += 0.2 * (W**2).mean()\n",
        "\n",
        "  if i % 10 == 0:\n",
        "    print(f\"{i}: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set grad to zero\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  # update weights\n",
        "  # with torch.no_grad():\n",
        "  #     W -= 50 * W.grad\n",
        "\n",
        "  W.data += -50 * W.grad\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9Y-BrKSI837",
        "outputId": "908b980d-8f6a-4a08-81b7-d4b0c93889f7"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 4.5036\n",
            "10: 2.6134\n",
            "20: 2.4748\n",
            "30: 2.4243\n",
            "40: 2.4001\n",
            "50: 2.3867\n",
            "60: 2.3788\n",
            "70: 2.3738\n",
            "80: 2.3706\n",
            "90: 2.3684\n",
            "100: 2.3670\n",
            "110: 2.3660\n",
            "120: 2.3653\n",
            "130: 2.3649\n",
            "140: 2.3645\n",
            "150: 2.3643\n",
            "160: 2.3642\n",
            "170: 2.3640\n",
            "180: 2.3640\n",
            "190: 2.3639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling"
      ],
      "metadata": {
        "id": "RbdWPxYWY-ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = []\n",
        "\n",
        "for i in range(10):\n",
        "  out = []\n",
        "  ix1,ix2 = 0,0\n",
        "  while True:\n",
        "    xenc = F.one_hot(torch.tensor([ix1,ix2]), num_classes = 27).float()\n",
        "    xenc = xenc.view(-1, 27*2)\n",
        "\n",
        "    logits = xenc @ W\n",
        "    counts = logits.exp()\n",
        "    p = counts / counts.sum(1, keepdims = True)\n",
        "\n",
        "    ix1 = ix2\n",
        "    ix2 = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "\n",
        "  names.append(\"\".join(out))\n",
        "\n",
        "print(names)\n",
        "loss_func(names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylEzLv4FYqRS",
        "outputId": "84c5e5a1-5ee5-498b-c2e4-bb037f760db5"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ouray.', 'aivak.', 'xa.', 'umysha.', 'chzmayla.', 'arber.', 'alyalas.', 'ir.', 'aan.', 'eryor.']\n",
            "log_likelihood=tensor(-155.0886)\n",
            "nll=tensor(155.0886)\n",
            "2.6739416122436523\n"
          ]
        }
      ]
    }
  ]
}